{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "import numpy as np\n",
    "import os\n",
    "import pyvista as pv\n",
    "import sys\n",
    "# sys.path.insert(0, '/home/pandu/Panresearch_local/PPP_Utility')\n",
    "# from panpv import panmesh as pm\n",
    "from os import listdir\n",
    "import pdb\n",
    "import torch_geometric\n",
    "import torch\n",
    "import mesh2graph_utility as mutl\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data, Batch, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total num of data: 89\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import vtk\n",
    "path = \"../../data/cases/dataset1/\"\n",
    "file_name_list = os.listdir(path)\n",
    "file_name_list = sorted(file_name_list, key=lambda x:float(re.findall(\"(\\d+)\",x)[0]))\n",
    "N = len(file_name_list); print('total num of data:',N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vtk2vtp(invtkfile, outvtpfile, binary=False):\n",
    "    \"\"\"What it says on the label\"\"\"\n",
    "    reader = vtk.vtkUnstructuredGridReader()\n",
    "    reader.SetFileName(invtkfile)\n",
    "    reader.Update()\n",
    "\n",
    "    reader2 = vtk.vtkGeometryFilter()\n",
    "    reader2.SetInputData(reader.GetOutput())\n",
    "    reader2.Update\n",
    "    writer = vtk.vtkXMLPolyDataWriter()\n",
    "    writer.SetFileName(outvtpfile)\n",
    "    if binary:\n",
    "        writer.SetFileTypeToBinary()\n",
    "    writer.SetInputConnection(reader2.GetOutputPort())\n",
    "    writer.Update()\n",
    "\n",
    "mesh_list = []\n",
    "files = []\n",
    "for i in range(N):\n",
    "    invtkfile = '../../data/cases/dataset1/'+file_name_list[i]+'/Mapped_Blade_Surface.vtk'\n",
    "    outvtpfile = '../../data/cases/dataset1/'+file_name_list[i]+'/Mapped_Blade_Surface.vtp'\n",
    "    vtk2vtp(invtkfile, outvtpfile,binary=False)\n",
    "    mesh_list.append(pv.read(outvtpfile))\n",
    "    files.append(outvtpfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vtk\n",
    "from torch_geometric.utils import to_undirected\n",
    "\n",
    "def cellArrayDivider(input_array):\n",
    "    N = len(input_array)\n",
    "    cursor = 0\n",
    "    head_id = []\n",
    "    segs = []\n",
    "    \n",
    "    while(cursor<N):\n",
    "        head_id.append(cursor)\n",
    "        segs.append(input_array[cursor+1:cursor+input_array[cursor]+1])\n",
    "        cursor = cursor+input_array[cursor]+1\n",
    "        # print(cursor)\n",
    "    return segs\n",
    "\n",
    "def readvtp(file_name):\n",
    "    reader = vtk.vtkPolyDataReader()\n",
    "    reader.SetFileName(file_name)\n",
    "    reader.Update()\n",
    "\n",
    "    return reader.GetOutput()\n",
    "\n",
    "def vtk2GraphVertex(input_file, with_data = False, p_arrayid = 0, wss_arrayid = 1):\n",
    "    if type(input_file) == str:\n",
    "        # aorta_vtk = readvtp(input_file)\n",
    "        rotorblade = pv.read(input_file)\n",
    "    else:\n",
    "        rotorblade = input_file\n",
    "    segs = np.array(cellArrayDivider(rotorblade.faces))\n",
    "    points = np.array(rotorblade.points,dtype = np.float32)\n",
    "    nodal_normals = np.array(rotorblade.point_normals,dtype = np.float32)\n",
    "    if with_data == True:\n",
    "        nodal_pressure = rotorblade.point_data['MappedAbsoluteTotalPressure']\n",
    "        nodal_wss = rotorblade.point_data['MappedTau']\n",
    "\n",
    "    nodal_stmdist = rotorblade.point_data['MappedDerivedVelocityMagnitude']  \n",
    "    nodal_features = np.array(nodal_normals, dtype = np.float32)\n",
    "    transform = torch_geometric.transforms.FaceToEdge(remove_faces=False)\n",
    "    if with_data == True:\n",
    "        nodal_labels = np.hstack((np.array(nodal_pressure,dtype = np.float32)[:,np.newaxis], np.array(nodal_wss,dtype = np.float32)[:,np.newaxis])) # four dimensions\n",
    "        readme = {'nodal_features':'normalx, normaly, normalz',\n",
    "                # 'edge_features':'d_coordinatex, d_coordinatey, d_coordinatez, d_coordinatenorm',\n",
    "                'nodal_pos':'corrdinatex, corrdinatey, corrdinatez',\n",
    "                'nodal_lables':'pressure, wss',\n",
    "                'nodal_norms':'normalx, normaly, normalz',\n",
    "                'nodal_stmdist': 'stmdist', 'face':'triangles'}\n",
    "        mesh_graph = Data(x = torch.tensor(nodal_features), #edge_index = torch.tensor(edge_connectivity.T),\n",
    "                        # edge_attr = torch.tensor(edge_features), \n",
    "                        y = torch.tensor(nodal_labels), \n",
    "                        pos = torch.tensor(points), norm = torch.tensor(nodal_normals), stmdist = torch.tensor(np.array(nodal_stmdist,dtype = np.float32)[:,np.newaxis]),\n",
    "                        face = torch.tensor(np.array(segs.T)))\n",
    "    else:\n",
    "        readme = {'nodal_features':'normalx, normaly, normalz',\n",
    "                # 'edge_features':'d_coordinatex, d_coordinatey, d_coordinatez, d_coordinatenorm',\n",
    "                'nodal_pos':'corrdinatex, corrdinatey, corrdinatez',\n",
    "                'nodal_norms':'normalx, normaly, normalz',\n",
    "                'nodal_stmdist': 'stmdist', 'face':'triangles'}\n",
    "        mesh_graph = Data(x = torch.tensor(nodal_features),#edge_index = torch.tensor(edge_connectivity.T),\n",
    "                        # edge_attr = torch.tensor(edge_features),\n",
    "                        pos = torch.tensor(points), norm = torch.tensor(nodal_normals),stmdist = torch.tensor(np.array(nodal_stmdist,dtype = np.float32)[:,np.newaxis]),\n",
    "                        face = torch.tensor(np.array(segs.T)))\n",
    "\n",
    "    mesh_graph_transformed = transform(mesh_graph)\n",
    "    return mesh_graph_transformed, readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset, Data\n",
    "from feature_descriptors import *\n",
    "\n",
    "\n",
    "class MyCustomDatasetVertex(Dataset):\n",
    "    def __init__(self,root,filenames):\n",
    "        self.filename = filenames\n",
    "        super(MyCustomDatasetVertex, self).__init__(root)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return self.filename\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "\n",
    "        return ['data_{:04d}.pt'.format(i) for i in range(4)]\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        idx = 0\n",
    "        for raw_path in self.raw_paths:\n",
    "            # converting vtp to graph\n",
    "            data,readme = vtk2GraphVertex(raw_path,with_data = True)\n",
    "            # adding features \n",
    "            fd = FeatureDescriptors()\n",
    "            data = fd(data)\n",
    "            torch.save(data, os.path.join(self.processed_dir, 'data_{:04d}.pt'.format(idx)))\n",
    "            idx += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.load(os.path.join(self.processed_dir, self.processed_file_names[idx]))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File (/storage/pandu/PPP_Heart/data/vertex/raw/aorta0000.vtp) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bberkley.esc.nd.edu/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m test_dataset \u001b[39m=\u001b[39m MyCustomDatasetVertex(\u001b[39m'\u001b[39;49m\u001b[39m../../data/vertex/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb Cell 7\u001b[0m in \u001b[0;36mMyCustomDatasetVertex.__init__\u001b[0;34m(self, root)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bberkley.esc.nd.edu/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,root):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bberkley.esc.nd.edu/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maorta\u001b[39m\u001b[39m{:04d}\u001b[39;00m\u001b[39m.vtp\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m)]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bberkley.esc.nd.edu/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39msuper\u001b[39;49m(MyCustomDatasetVertex, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root)\n",
      "File \u001b[0;32m~/anaconda3/envs/graphlab/lib/python3.10/site-packages/torch_geometric/data/dataset.py:87\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download()\n\u001b[1;32m     86\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process()\n",
      "File \u001b[0;32m~/anaconda3/envs/graphlab/lib/python3.10/site-packages/torch_geometric/data/dataset.py:170\u001b[0m, in \u001b[0;36mDataset._process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProcessing...\u001b[39m\u001b[39m'\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m    169\u001b[0m makedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir)\n\u001b[0;32m--> 170\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess()\n\u001b[1;32m    172\u001b[0m path \u001b[39m=\u001b[39m osp\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir, \u001b[39m'\u001b[39m\u001b[39mpre_transform.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    173\u001b[0m torch\u001b[39m.\u001b[39msave(_repr(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_transform), path)\n",
      "\u001b[1;32m/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb Cell 7\u001b[0m in \u001b[0;36mMyCustomDatasetVertex.process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bberkley.esc.nd.edu/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bberkley.esc.nd.edu/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m raw_path \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_paths:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bberkley.esc.nd.edu/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# converting vtp to graph\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bberkley.esc.nd.edu/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     data,readme \u001b[39m=\u001b[39m vtk2GraphVertex(raw_path,with_data \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bberkley.esc.nd.edu/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m# adding features \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bberkley.esc.nd.edu/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     fd \u001b[39m=\u001b[39m FeatureDescriptors()\n",
      "\u001b[1;32m/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb Cell 7\u001b[0m in \u001b[0;36mvtk2GraphVertex\u001b[0;34m(input_file, with_data, p_arrayid, wss_arrayid)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bberkley.esc.nd.edu/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvtk2GraphVertex\u001b[39m(input_file, with_data \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, p_arrayid \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, wss_arrayid \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bberkley.esc.nd.edu/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(input_file) \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bberkley.esc.nd.edu/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m         \u001b[39m# aorta_vtk = readvtp(input_file)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bberkley.esc.nd.edu/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m         rotorblade \u001b[39m=\u001b[39m pv\u001b[39m.\u001b[39;49mread(input_file)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bberkley.esc.nd.edu/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bberkley.esc.nd.edu/home/pandu/storage/PPP_Heart/code/sandbox/datasource.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m         rotorblade \u001b[39m=\u001b[39m input_file\n",
      "File \u001b[0;32m~/anaconda3/envs/graphlab/lib/python3.10/site-packages/pyvista/utilities/fileio.py:159\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, attrs, force_ext, file_format, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexpanduser(\u001b[39mstr\u001b[39m(filename)))\n\u001b[1;32m    158\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(filename):\n\u001b[0;32m--> 159\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFile (\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m) not found\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    161\u001b[0m \u001b[39m# Read file using meshio.read if file_format is present\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mif\u001b[39;00m file_format:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File (/storage/pandu/PPP_Heart/data/vertex/raw/aorta0000.vtp) not found"
     ]
    }
   ],
   "source": [
    "test_dataset = MyCustomDatasetVertex('../../data/vertex/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_id = 0\n",
    "demo,_ = vtk2GraphVertex(mesh_list[pick_id], with_data = True) # x is pos, y is pressure and tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    max, min  = torch.max(data ,dim = 0)[0], torch.min(data ,dim = 0)[0]\n",
    "    print('max, min', max,min)\n",
    "    norm_data = (data-min)/(max-min)*2-1\n",
    "    return norm_data, [max,min]\n",
    "def denormalize(data, maxmin = None):\n",
    "    max, min  = maxmin[0], maxmin[1]\n",
    "    denorm_data = (data+1)/2*(max-min)+min\n",
    "    return denorm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max, min tensor([127279.2500,    674.1190]) tensor([9.8850e+04, 1.2352e+00])\n",
      "normalized data tensor([[ 0.6006, -0.9215],\n",
      "        [ 0.5852, -0.8991],\n",
      "        [ 0.5634, -0.6746],\n",
      "        ...,\n",
      "        [ 0.4209, -0.6052],\n",
      "        [ 0.3443, -0.6269],\n",
      "        [ 0.3816, -0.7038]])\n"
     ]
    }
   ],
   "source": [
    "demo.ydenorm = demo.y\n",
    "demo.y, maxmin = normalize(demo.y) ;print('normalized data',demo.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge attr size torch.Size([60212, 4])\n",
      "edge attr: tensor([[ 2.2189e-04,  1.4070e-04,  8.6654e-05,  2.7666e-04],\n",
      "        [ 4.8425e-05,  2.3432e-04,  1.1091e-04,  2.6373e-04],\n",
      "        [-2.3447e-04,  5.8639e-05, -6.7937e-05,  2.5105e-04],\n",
      "        ...,\n",
      "        [-5.1278e-05, -7.4301e-06,  3.1101e-04,  3.1530e-04],\n",
      "        [-1.2711e-04,  1.2032e-04,  4.7548e-05,  1.8137e-04],\n",
      "        [-7.6798e-05, -2.1863e-04,  1.2378e-04,  2.6272e-04]])\n"
     ]
    }
   ],
   "source": [
    "# calculate the norm of edges \n",
    "xij = torch.stack([demo.pos[demo.edge_index[1,i]]-demo.pos[demo.edge_index[0,i]] for i in range(demo.edge_index.size()[1])])\n",
    "# calculate the norm of edges \n",
    "xijabs = torch.stack([torch.norm(demo.pos[demo.edge_index[1,i]]-demo.pos[demo.edge_index[0,i]] ) for i in range(demo.edge_index.size()[1])])\n",
    "demo.edge_attr = torch.cat((xij, xijabs.unsqueeze(1)),dim = 1); print('edge attr size',demo.edge_attr.size())\n",
    "print('edge attr:',demo.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_model(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=6, improved=False,\n",
    "                 cached=False, bias=True, fine_marker_dict=None, GCNtype = 'MGN'):\n",
    "        super().__init__()\n",
    "        self.GCNtype = GCNtype\n",
    "        channels = [in_channels]\n",
    "        channels += [hidden_channels] * (num_layers - 1)\n",
    "        channels.append(out_channels)\n",
    "\n",
    "        convs = []\n",
    "        for i in range(num_layers):\n",
    "            if GCNtype == 'MGN':\n",
    "                convs.append(MGNGraphNet(3, in_channels=channels[i], in_edge_channels=4, out_channels=channels[i+1],hidFeature=128,aggr='mean'))\n",
    "            if GCNtype == 'GCN':\n",
    "                convs.append(GCNConv(in_channels=channels[i], out_channels=channels[i+1]))\n",
    "        self.convs = torch.nn.ModuleList(convs)\n",
    "\n",
    "    def forward(self, data):\n",
    "        tmp = [data.featr3[:, 0][:, [0, 0, 0, 1, 1, 2], [0, 1, 2, 1, 2, 2]],\n",
    "        data.featr3[:, 1][:, [0, 0, 0, 1, 1, 2], [0, 1, 2, 1, 2, 2]],\n",
    "        data.featr3[:, 2].reshape(-1, 9)]\n",
    "        out = torch.hstack((torch.hstack(tmp), data.stmdist))\n",
    "        \n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            if self.GCNtype == 'MGN':\n",
    "                out = conv(out, data.edge_index,data.edge_attr) # .unsqueeze\n",
    "            if self.GCNtype == 'GCN':\n",
    "                # print('input size:',out.size())\n",
    "                # print('edge index size:',data.edge_index.size())\n",
    "                out = conv(out, data.edge_index)\n",
    "            out = F.relu(out)\n",
    "        # print('debug8',out.size())\n",
    "        \n",
    "        if self.GCNtype == 'MGN':\n",
    "            out = self.convs[-1](out, data.edge_index,data.edge_attr) # .unsqueeze\n",
    "        if self.GCNtype == 'GCN':\n",
    "            out = self.convs[-1](out, data.edge_index) # .unsqueeze\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('graphlab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86ebb72f6481a5ec0210b52d49d4073c917056b34ec47fc43f28ddec02b94fa7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
